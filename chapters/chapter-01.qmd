\mainmatter

# What is a causal question? {#sec-causal-question}

{{< include 00-setup.qmd >}}

## Schrödinger's Causality

The heart of causal analysis is the causal question; it dictates what data we analyze, how we analyze it, and to which populations we make inferences about. This book, being applied in nature, deals primarily with the analysis stage of causal inference. Relative to the complexity of specifying a good causal question, the analysis stage is considerably simpler. In the first six chapters of this book, we'll discuss what a causal question is, how to improve our questions, and consider some examples. 

Causal questions are part of a broader set of questions we can ask with statistical techniques, related to the primary tasks of data science: description, prediction, and causal inference @CITATION. Unfortunately, these tasks are often muddled by both the techniques we use (regression, for instance, is useful for all three tasks) as well as the way we talk about them. When researchers are interested in causal inference from non-randomized data, we often use euphemistic language like "association" rather declaring our intent to estimate a causal effect @CITATION.

In a recent study of the language of analyses in epidemiologic research, for instance, the most common root word describing the estimated effect was "associate", but many researchers also felt that "associate" implied at least *some* causal effect (@fig-word-ranking). Only around 1% of the studies analyzed used the root word "cause" at all. Yet, a third of studies had action recommendation, and researchers rated 80% of these recommendations as having at least some causal implication. Often, these studies have stronger action recommendations (implying causal effects) than the implied be the description of the effect (root words like "associate" and "compare"). Despite how many studies implied that the goal was causal inference, only about 4% used formal causal models like those discussed in this book, although most included some discussion of how such a cause might be justified by previous research or theory.

```{r}
#| label: "fig-word-ranking"
#| fig.cap: "TODO"
#| echo: false

rankings <-  read_csv(here::here("data/word_rankings.csv")) |> 
  janitor::clean_names() 

lvls <- rankings |> 
  count(rating, root_word) |> 
  filter(rating == "Strong") |>
  arrange(desc(n)) |> 
  mutate(root_word = fct_inorder(root_word)) |> 
  pull(root_word) |> 
  levels()

rankings |>
  count(rating, root_word) |> 
  mutate(root_word = factor(root_word, levels = lvls)) |> 
  filter(!is.na(root_word)) |> 
  group_by(rating) |> 
  mutate(rank = n / sum(n)) |> 
  ungroup() |> 
  ggplot(aes(x = rank, y = root_word, fill = rating)) + 
  geom_col(position = position_fill(reverse = TRUE)) +
  scale_fill_viridis_d(option = "mako", direction = -1)  +
  labs(y = "root word") 
```


Instead of clear questions with obvious assumptions and goals, we end up with "Schrödinger's causal inference":

> Our results suggest that
"Schrödinger's causal inference," - where studies avoid stating (or
even explicitly deny) an interest in estimating causal effects yet are otherwise embedded with
causal intent, inference, implications, and recommendations - is common. @CITATION

A good first step to address this problem is to recognize the questions about description, prediction, and explanation are fundamentally different. Data science in industry isn't quite as burdened by Schrödinger's causal inference as the academic sciences, but being explicit here is still useful. For instance, when a stakeholder asks for "drivers" of a particular event, what are they asking? For a model to predict the event? For a deeper understanding of what causes the event? It's a vague request, and helping to clarify our goals helps. When we're clear about our goals, we can use the other approaches more effectively (and, as we'll see, both descriptive analysis and prediction models are still useful when the goal is to make causal inferences). 

## Description, prediction, and explanation



## Causal Assumptions

Like most statistical approaches, the validity of a causal analysis depends on how well certain assumptions are met. The most common assumptions across the approaches we describe in this book are:

1. Consistency: the potential outcome for a subject given their exposure is the observed outcome. Analogously, if we had a time machine through which we could assign the same exposure to the same subject many times, we would observe the same outcome in all experiments. Consistency can imply that manipulability of exposure is necessary [TODO explain this more clearly (or maybe we move this point to the target trial section)] [ref paragraph 3](https://journals.lww.com/epidem/fulltext/2009/01000/the_consistency_statement_in_causal_inference__a.3.aspx)

2. Exchangeability: within levels of relevant variables (confounders), exposed and unexposed subjects have an equal likelihood of experiencing any outcome prior to exposure; i.e. the exposed and unexposed subjects are exchangeable. This assumption is sometimes referred to as "no unmeasured confounding."

3. Positivity: within each level and combination of the study variables used to achieve exchangeability, there are exposed and unexposed subjects.

4. No interference: the outcome (observed or counterfactual) for any subject does not depend on another subject's exposure 
[TODO: Make sure we've defined "counterfactual" in one of the first two sections above]

5. Well defined exposure: for each value of the exposure, there is no difference between subjects in the delivery of that exposure. Put another way, multiple versions of the treatment do not exist.

Assumptions 1 through 3 are typically referred to as "identifiability conditions" since we need them to hold in order to identify causal estimates. [TODO: SUTVA callout box re: assumptions 4 and 5]. Technically, assumption 5 (well defined exposure) is part of assumption 1 (consistency), but we find it useful in practice to check the concerns separately.

Causal assumptions can be difficult to verify and may not hold for many data collection strategies. We cannot overstate the importance of checking these criteria to the extent possible! Following any of the recipes in this book are unlikely to give valid answers if the causal assumptions are badly violated. 

### Checking consistency

A good example is effect of [SES on health](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4912021/): the assumption is that if you vary the components within the same SES level the same effect would occur. Can likely simulate some R code to show increasing income while lowering education to get same SES might result in different outcome. Make a note that this covers assumption 5 as well.

### Checking exchangeability

### Checking positivity

### Checking interference

## When do standard methods succeed and fail?
