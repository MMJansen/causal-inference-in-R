\mainmatter

# What is a causal question? {#sec-causal-question}

{{< include 00-setup.qmd >}}

## Schrödinger's Causality

The heart of causal analysis is the causal question; it dictates what data we analyze, how we analyze it, and to which populations we make inferences about.
This book, being applied in nature, deals primarily with the analysis stage of causal inference.
Relative to the complexity of specifying a good causal question, the analysis stage is considerably more straightforward.
In the first six chapters of this book, we'll discuss what a causal question is, how to improve our questions, and consider some examples.

Causal questions are part of a broader set of questions we can ask with statistical techniques related to the primary tasks of data science: description, prediction, and causal inference [@hernán2019].
Unfortunately, these tasks are often muddled by both the techniques we use (regression, for instance, is helpful for all three tasks) and the way we talk about them.
When researchers are interested in causal inference from non-randomized data, we often use euphemistic language like "association" instead of declaring our intent to estimate a causal effect [@Hernán2018].

In a recent study of the language of analyses in epidemiologic research, for instance, the most common root word describing the estimated effect was "associate," but many researchers also felt that "associate" implied at least *some* causal effect (@fig-word-ranking) [@haber_causal_language].
Only around 1% of the studies analyzed used the root word "cause" at all.
Yet, a third of studies had action recommendations, and researchers rated 80% of these recommendations as having at least some causal implication.
Often, these studies have stronger action recommendations (alluding to causal effects) than those implied by the description of the effect (root words like "associate" and "compare").
Despite how many studies implied that the goal was causal inference, only about 4% used formal causal models like those discussed in this book. However, most discussed how such a cause might be justified by previous research or theory.

```{r}
#| label: "fig-word-ranking"
#| fig.cap: "Rankings of causal strength of root words used by researchers. Root words with more Strong rankings have stronger causal implications than those with many None or Weak rankings. Data from Haber et al."
#| fig.height: 9
#| echo: false

rankings <-  read_csv(here::here("data/word_rankings.csv"), show_col_types = FALSE) |> 
  janitor::clean_names() 

lvls <- rankings |> 
  count(rating, root_word) |> 
  filter(rating == "Strong") |>
  arrange(desc(n)) |> 
  mutate(root_word = fct_inorder(root_word)) |> 
  pull(root_word) |> 
  levels()

rankings |>
    count(rating, root_word) |> 
    mutate(root_word = factor(root_word, levels = lvls)) |> 
    filter(!is.na(root_word)) |> 
    group_by(rating) |> 
    mutate(rank = n / sum(n)) |> 
    ungroup() |> 
    drop_na(rating) |> 
    mutate(rating = factor(rating, levels = c("None", "Weak", "Moderate", "Strong"))) |> 
    ggplot(aes(x = rank, y = root_word, fill = rating)) + 
    geom_col(position = position_fill(reverse = TRUE)) +
    scale_fill_viridis_d( direction = -1)  +
    labs(y = "root word") +
    theme(axis.ticks = element_blank(), panel.grid = element_blank())
```

Instead of clear questions with obvious assumptions and goals, we end up with "Schrödinger's causal inference":

> Our results suggest that "Schrödinger's causal inference," - where studies avoid stating (or even explicitly deny) an interest in estimating causal effects yet are otherwise embedded with causal intent, inference, implications, and recommendations - is common.
>
> --- @haber_causal_language

An excellent first step to address this problem is recognizing that questions about description, prediction, and explanation are fundamentally different.
Data science in industry isn't quite as burdened by Schrödinger's causal inference as the academic sciences, but being explicit in the differences in these analyses is still helpful.
For instance, when a stakeholder asks for "drivers" of a particular event, what are they asking?
For a model to predict the event?
For a deeper understanding of what causes the event?
It's a vague request, but it smacks of causal interest to us.
When we're clear about our goals, we can use all three approaches more effectively (and, as we'll see, both descriptive analysis and prediction models are still helpful when the goal is to make causal inferences).

## Description, prediction, and explanation

## Diagraming a causal claim

Diagramming sentences is a grammatical method used to visually represent the structure of a sentence, occasionally taught in grammar school. In this technique, sentences are deconstructed into their constituent parts, such as subjects, verbs, objects, and modifiers, and then displayed using a series of lines and symbols. The arrangement of these elements on the diagram reflects their syntactic roles and how they interact within the sentence's overall structure. By breaking down sentences into these visual representations, diagramming can help learners grasp the nuances of sentence construction, identify grammatical errors, and appreciate the intricate connections between words. We can apply a similar idea to *causal claims*. Here is an example of how one might diagram a causal claim. We've pulled out the *cause*, the *effect*, the *subject* (for whom?), and the *timing* (when?).  

```{r}
#| echo: false
#| fig-cap: "Example of diagraming a causal claim"
#| fig-height: 2
#| label: fig-diagram-1
library(ggplot2)

data <- data.frame(labels = c("cause", "effect", "for whom?", "when?"),
                   x = c(1.25, 1.75, 1.25, 1.55),
                   y = c(1, 1, 0.8, 0.7),
                   angle = c(0, 0, -30, 0))  

ggplot(data, aes(x = x, y = y)) +
  geom_text(aes(label = labels, angle = angle, vjust = 0), 
            size = 7) +
  geom_segment(aes(x = 1, xend = 2, y = 0.95, yend = 0.95)) +  
  geom_segment(aes(x = 1.5, xend = 1.5, y = 0.95, yend = 1.1)) +
  geom_segment(aes(x = 1, xend = 1.35, y = 0.95, yend = 0.65)) +
  geom_segment(aes(x = 1.35, xend = 1.65, y = 0.65, yend = 0.65)) +
  theme_void()
```

Let's start with a basic causal question: **Does smoking cause cancer?**

The causal claim here could be *smoking causes cancer*. @fig-diagram-2 shows a potential diagram of this causal claim.



```{r}
#| echo: false
#| label: fig-diagram-2
#| fig-height: 2
#| fig-cap: "Diagram of the causal claim \"smoking causes cancer\"."
data <- data.frame(labels = c("smoking", "lung cancer", "for everyone?", "immediately?"),
                   x = c(1.25, 1.75, 1.25, 1.55),
                   y = c(1, 1, 0.8, 0.7),
                   angle = c(0, 0, -30, 0))  

ggplot(data, aes(x = x, y = y)) +
  geom_text(aes(label = labels, angle = angle, vjust = 0), 
            size = 7) +
  geom_segment(aes(x = 1, xend = 2, y = 0.95, yend = 0.95)) +  
  geom_segment(aes(x = 1.5, xend = 1.5, y = 0.95, yend = 1.1)) +
  geom_segment(aes(x = 1, xend = 1.35, y = 0.95, yend = 0.65)) +
  geom_segment(aes(x = 1.35, xend = 1.65, y = 0.65, yend = 0.65)) +
  theme_void()
```

Let's try to get more specific. A study was published in *JAMA* (the Journal of the American Medical Association) in 2005 titled "Effect of Smoking Reduction on Lung Cancer Risk". This study concluded: "Among individuals who smoke 15 or more cigarettes per day, smoking reduction by 50% significantly reduces the risk of lung cancer". [@godtfredsen2005effect] The study goes on to describe the time frame studied as 5-10 years. Let's diagram this causal claim.

```{r}
#| echo: false
#| fig-cap: "Example diagram of a more specific causal claim based on results from @godtfredsen2005effect"
#| label: fig-diagram-3

data <- data.frame(labels = c("Reducing smoking by 50%", "Reduced lung cancer", "People who\nsmoke 15+\ncigarettes per day", "between 5-10 years"),
                   x = c(1, 2, .83, 1.4),
                   y = c(1, 1, 0.77, 0.7),
                   angle = c(0, 0, -48, 0))  

ggplot(data, aes(x = x, y = y)) +
  geom_text(aes(label = labels, angle = angle, vjust = 0), size = 5) +
  geom_segment(aes(x = 0.5, xend = 2.5, y = 0.95, yend = 0.95)) +  
  geom_segment(aes(x = 1.5, xend = 1.5, y = 0.95, yend = 1.1)) +
  geom_segment(aes(x = 0.5, xend = 1, y = 0.95, yend = 0.65)) +
  geom_segment(aes(x = 1, xend = 1.5, y = 0.65, yend = 0.65)) +
  xlim(c(0.5, 2.5)) +
  ylim(c(0.5, 1.2)) +
  theme_void()
```

Translating this idea into asking good causal questions, we can map the following terms that you will see throughout this book to these diagrams: *exposure* (the cause), *outcome* (the effect), *eligibility criteria* (for whom?), and *follow up period* (when?).

```{r}
#| echo: false
#| label: fig-diagram-4
#| fig-height: 2
#| fig-cap: "Example diagram mapped to causal analysis terminology"
data <- data.frame(labels = c("exposure", "outcome", "eligibility criteria", "follow up"),
                   x = c(1.25, 1.75, 1.25, 1.55),
                   y = c(1, 1, 0.8, 0.7),
                   angle = c(0, 0, -30, 0))  

ggplot(data, aes(x = x, y = y)) +
  geom_text(aes(label = labels, angle = angle, vjust = 0), 
            size = 7) +
  geom_segment(aes(x = 1, xend = 2, y = 0.95, yend = 0.95)) +  
  geom_segment(aes(x = 1.5, xend = 1.5, y = 0.95, yend = 1.1)) +
  geom_segment(aes(x = 1, xend = 1.35, y = 0.95, yend = 0.65)) +
  geom_segment(aes(x = 1.35, xend = 1.65, y = 0.65, yend = 0.65)) +
  theme_void()
```

Asking good causal questions means we map the *question* to the observable *evidence*. Let's return to the smoking example. Our initial question was: *Does smoking causes lung cancer?*; using our study, the evidence shows *For people who smoke 15+ cigarettes a day, reducing smoking by 50% reduces the risk of lung cancer over 5-10 years*. Do these match? Not quite. Let's update our question to match what the study actually was able to show: *For people who smoke 15+ cigarettes a day, does reducing smoking by 50% reduce the lung cancer risk over 5-10 years?*. Honing this skill, asking answerable causal questions, is important, and one that we will discuss throughout this book.
