# Causal estimands

## Estimands, Estimators, Estimates

The **estimand** is the *target of interest*, the **estimator** is the method by which we approximate this estimand using data, and the **estimate** is the value we get when we plug our data into the estimator.
You can think of the **estimand** as glossy picture of a beautiful cake that we are trying to bake, the **estimator** as the recipe, and the **estimate** as the cake that we actually pull out of our oven.

So far we have been estimating the average treatment effect, that is the effect of the exposure of interest averaged across the whole population.
The **estimand** here is the expected value of the difference in potential outcomes across all individuals:

$$E[Y(1) - Y(0)]$$

The **estimator** we use depends on the method we've chosen.
For example, in a randomized controlled trial, our estimator could just be the average outcome among those who received the exposure minus the average outcome among those who did not.

$$\sum_{i=1}^{N}\frac{Y_i\times X_i}{N_{\textrm{exposed}}} - \frac{Y_i\times (1-X_i)}{N_{\textrm{unexposed}}}$$

Where $X$ is just an indicator for exposure ($X = 1$ for the exposed and $X = 0$ for the unexposed.) Suppose we have some randomized controlled trial data for 100 participants in a dataset called `rct`.
Here is some code to simulate such a data set.

```{r, eval = FALSE}
set.seed(928)
rct <- tibble(
  # generate the exposure, x, from a binomial distribution 
  # with the probability exposure (the probability x = 1) of 0.5 
  x = rbinom(100, 1, 0.5), 
  # generate the "true" average treatment effect of 1
  # we use rnorm(100) to add the random error term that is normally
  # distributed with a mean of 0 and a standard deviation of 1
  y = x + rnorm(100)
)
```

Here the exposure is `x` and the outcome is `y`.
The true average treatment effect is 1.
Below are two ways to estimate this in R.

```{r, echo = FALSE}
set.seed(928)
rct <- tibble(
  x = rbinom(100, 1, 0.5),
  y = x + rnorm(100)
)
rct |>
  summarise(
    n_exposed = sum(x),
    n_unexposed = sum(1 - x),
    estimate = sum(
    (y * x) / n_exposed - 
      y * (1 - x) / n_unexposed
  )) |> pull(estimate) -> estimate
```

```{r}
rct
```

```{r}
rct |>
  summarise(
    n_exposed = sum(x),
    n_unexposed = sum(1 - x),
    estimate = sum(
    (y * x) / n_exposed - 
      y * (1 - x) / n_unexposed
  ))

rct |>
  group_by(x) |>
  summarise(avg_y = mean(y)) |>
  pivot_wider(names_from = x, 
              values_from = avg_y, 
              names_prefix = "x_") |>
  summarise(estimate = x_1 - x_0)
```

Because $X$, the exposure, was randomly assigned, this estimator results in an unbiased estimate of our estimand of interest.

Notice here that while the "true" causal effect is 1, this estimate is not exactly 1, it is `r round(estimate, 3)`.
Why the difference?
This randomized controlled trial was run on a sample of 100 participants, not the whole population.
As that sample increases, our estimate will get closer to the truth.
Let's try that.
Let's simulate the data again, but increase the sample size from 100 to 100,000

```{r}
set.seed(928)
rct <- tibble(
  x = rbinom(100000, 1, 0.5), 
  y = x + rnorm(100000)
)

rct |>
  summarise(
    n_exposed = sum(x),
    n_unexposed = sum(1 - x),
    estimate = sum(
    (y * x) / n_exposed - 
      y * (1 - x) / n_unexposed
  ))
```

Notice now the estimate is 1.01, much closer to the true average treatment effect, 1.

If $X$ had not been randomly assigned, we could use the pre-exposure covariates to estimate the conditional probability of $X$ (the propensity score), and incorporate this probability in a *weight* $(w_i)$ to estimate this causal effect.
For example, we could use the following *estimator* to *estimate* our average treatment effect *estimand*:

$$\frac{\sum_{i=1}^NY_i\times X_i\times w_i}{\sum_{i=1}^NX_i\times w_i}-\frac{\sum_{i=1}^NY_i\times(1-X_i)\times w_i}{\sum_{i=1}^N(1-X_i)\times w_i}$$

Depending on the goal of the study, or the causal question at hand, different *estimands* may be of of interest.
Here, we will outline the most common causal estimands, their target populations, the causal questions they may help answer, and the methods used to estimate them.[@greifer2021choosing]

### Average treatment effect

A common estimand is the average treatment effect (ATE).
The target population is the *full sample* or population of interest.
The **estimand** here is the expected value of the difference in potential outcomes across all individuals:

$$E[Y(1) - Y(0)]$$

An example research question is "Should a policy be applied to all eligible patients?"[@greifer2021choosing]

Most randomized controlled trials are designed with the ATE as the target estimand.
In a non-randomized setting, the ATE can be estimated using full matching, where each observation in the exposed group is matched to at least one observation in the control group (and vice versa) without replacement.
Alternatively, the following inverse probability weight will allow for the ATE to be estimated using propensity score weighting.

$$w_{ATE} = \frac{X}{p} + \frac{(1 - X)}{1 - p}$$

In other words, the weight is one over the propensity score for those in the exposure group and one over one minus the propensity score for the control group.
Intuitively, this weight equates to the inverse probability of being in the exposure group that you were observed to be in.

Let's dig a bit deeper into this causal estimand using the Touring Plans data.
Recall in Chapter 4 we examined the relationship between whether there were "Extra Magic Hours" in the morning and the average wait time for the Seven Dwarfs Mine Train the same day between 5pm and 6pm.
Let's reconstruct our data set, `seven_dwarfs` and fit the same propensity score model specified previously.

```{r}
library(broom)
library(touringplans)

seven_dwarfs <- seven_dwarfs_train_2018 |>
  filter(hour == 17)

seven_dwarfs_with_ps <- glm(
  extra_magic_morning ~ wdw_ticket_season + close + weather_wdwhigh,
  data = seven_dwarfs,
  family = binomial()
) |>
  augment(type.predict = "response", data = seven_dwarfs)
```

Let's examine a table of the variables of interest in this data frame.
To do so, we are going to use the `tbl_summary()` function from the {gtsummary} package.

```{r}
library(gtsummary)

tbl_summary(seven_dwarfs_with_ps, 
            by = extra_magic_morning, 
            include = c(wdw_ticket_season, close, weather_wdwhigh)) |>
  add_overall() # add an overall column to the table
```

From this table, there were 291 days that did not have extra magic hours in the morning and 56 that did.
We also see 30% of the extra magic mornings were during peak season compared to 21% of the non-extra magic mornings that were during peak season.
Additionally, days that had extra magic mornings were more likely to close at 6pm (18:00:00) compared to non-magic hour mornings.
The median temperature on days with extra magic hour mornings is a bit lower (79 degrees) compared to non-extra magic hour morning days.

Now let's construct our propensity score weight to estimate the ATE.

```{r}
seven_dwarfs_with_ps <- seven_dwarfs_with_ps |>
  mutate(w_ate = extra_magic_morning / .fitted + 
           (1 - extra_magic_morning) / (1 - .fitted))
```

The {gtsummary} package allows the creation of *weighted* tables.
To do this, we need to load the {survey} package and create a survey design object.
Recall that the {survey} package is currently the best way to incorporate weights in various R functions.
This has a historical explanation, as the techniques needed to incorporate weights historically were used for survey analyses.
Even though we are not doing a survey analysis, the same techniques are useful for our propensity score weights.

```{r}
library(survey)
seven_dwarfs_svy <- svydesign(
  ids = ~ 1,
  data = seven_dwarfs_with_ps,
  weights = ~w_ate
)
tbl_svysummary(seven_dwarfs_svy, 
            by = extra_magic_morning, 
            include = c(wdw_ticket_season, close, weather_wdwhigh)) |>
  add_overall() # add an overall column to the table
```

```{r}
ggplot() +
  geom_histogram(
    data = seven_dwarfs_with_ps |> filter(extra_magic_morning == 1),
    aes(x = .fitted),
    fill = "orange",
    bins = 40
  ) +
  geom_histogram(
    data = seven_dwarfs_with_ps |> filter(extra_magic_morning == 0),
    aes(
      x = .fitted,
      y = -after_stat(count)
    ),
    fill = "cornflower blue",
    bins = 40
  ) +
  scale_y_continuous("Count", labels = abs) +
  scale_x_continuous("Propensity Score")
```

### Average treatment effect among the treated

The target population to estimate the average treatment effect among the treated (ATT) is the *exposed* (treated) population.
The causal estimand conditions on those in the exposed group.

$$E[Y(1) - Y(0) | X = 1]$$

Example research questions where the ATT is of interest could include "Should we stop our marketing campaign to those currently receiving it?" or "Should medical providers stop recommending treatment for those currently receiving it?"[@greifer2021choosing]

### Average treatment effect among the controls

The target population to estimate the average treatment effect among the control (unexposed) (ATC / ATU) is the *unexposed* (control) population.
The causal estimand conditions on those in the unexposed group.

$$E[Y(1) - Y(0) | X = 0]$$

Example research questions where the ATC is of interest could include "Should we send our marketing campaign to those not currently receiving it?" or "Should medical providers begin recommending treatment for those not currently receiving it?"[@greifer2021choosing]

### Average treatment effect among the evenly matchable

The target population to estimate the average treatment effect among the evenly matchable (ATM) is the evenly matchable.
The causal estimand conditions on those deemed "evenly matchable" by some distance metric.

$$E[Y(1) - Y(0) | M_d = 1]$$

Here $d$ denotes a distance measure and $M_d=1$ indicates that a unit is evenly matchable under that distance measure.[@samuels2017aspects; @d2018improving] Example research questions where the ATM is of interest could include "Should those at clinical equipoise receive the exposure?"[@greifer2021choosing]
