# Building propensity score models

:::def-box
A **propensity score** is the probability of being in the exposure group, conditioned on observed covariates.
:::

@rosenbaum1983central showed in observational studies, conditioning on propensity scores can lead to unbiased estimates of the exposure effect as long as certain assumptions hold:

1. There are no unmeasured confounders
2. Every subject has a nonzero probability of receiving either exposure

There are many ways to estimate the propensity score; typically people use logistic regression. This is done by fitting a logistic regression model predicting the exposure using known covariates. Each individuals' predicted values are the propensity scores. In R, a logistic regression model can be fit using the `glm()` function. Below is pseudo-code. The first argument is the model, with the exposure on the left side and the confounders on the right. The data frame is passed to the `data` argument and the `family = binomial()` argument to denote the model should be fit using logistic regression (as opposed to a different generalized linear model).

```{r, eval = FALSE}
glm(
  exposure ~ confounder_1 + confounder_2, 
  data = df,
  family = binomial()
)
```

We can extract the propensity scores by pulling out the predictions on the probability scale. Using the `augment()` function from the broom package, we can extract these propensity scores and add them to our original data frame. The argument `type.predict` is set to `"response"` to indicate that we want to extract the predicted values on the *probability* scale. By default, these will be on the linear logit scale. The `data` argument contains the original data frame. This code will output a new data frame consisting of all components in `df` with six additional columns corresponding to the logistic regression model that was fit. The `.fitted` column is the propensity score.

```{r, eval = FALSE}
glm(
  exposure ~ confounder_1 + confounder_2, 
  data = df,
  family = binomial()
) %>%
  augment(type.predict = "response", data = df)
```

Let's look at an example. 

## Extra Magic Hours

Historically, guests who stayed in a Walt Disney World resort hotel were able to access the park during "Extra Magic Hours" during which the park was closed to all other guests. These extra hours could be in the morning or evening. In 2018, there were four theme parks that provided "Extra Magic Hours" at Disney World: Magic Kingdom Park, EPCOT, Disney's Hollywood Studios, and Disney's Animal Kingdom Park. Typically, each day one park was selected to have these "Extra Magic Hours". We are interested in examining the relationship between whether a park had "Extra Magic Hours" in the morning and the average wait time for attractions the same day between 5pm and 6pm. Below is a proposed DAG for this question.

```{r, echo = FALSE, message = FALSE, warning = FALSE, fig.cap = "Proposed DAG for the relationship between Extra Magic Hours in the morning at a particular park and the average wait time between 5pm and 6pm."}
library(ggdag)

coord_dag <- list(
  x = c(Park = 0, Season = 0, close = 0, x = 1, y = 2),
  y = c(Park = -1, Season = 1, close = 0.25, x = 0, y = 0)
)

labels <- c(
  x = "Extra Magic Morning",
  y = "Average wait between 5pm and 6pm",
  Park = "Park",
  Season = "Ticket Season",
  close = "Time park closed"
)

dagify(
  y ~ x,
  y ~ close,
  y ~ Park,
  y ~ Season,
  x ~ Park,
  x ~ close,
  x ~ Season,
  coords = coord_dag,
  labels = labels
) %>%
  ggdag(use_labels = "label", text = FALSE) + 
  theme_void()
```

Here we are proposing that there are three confounders, the park where the extra time was given, the time the park closed, and the ticket season: value, regular, or peak. We can build a propensity score model using the `touringplans_2018` data set from the touringplans package. First we need to subset the data to only include average wait times between 6 and 7 pm.

```{r}
library(tidyverse)
library(broom)
library(touringplans)

df <- touringplans_2018 %>%
  filter(hour == 17)

glm(
  extra_magic_morning ~ park + wdw_ticket_season + close,
  data = df,
  family = binomial()
) %>% 
  augment(type.predict = "response", data = df) -> df
```

Let's take a look at these propensity scores. Below, the propensity scores are shown in the `.fitted` column for the first 10 observations. The propensity score here is the probability that a given date will have Extra Magic Hours in the morning given the observed covariates, in this case Park and Ticket Season. For example, on June 30, 2018 there was a 51.1\% chance that there would be Extra Magic Hours at Disney's Hollywood Studios given the Ticket Season (peak in this case) and time of park closure (11pm). On this particular day, there were *not* Extra Magic Hours in the morning (as indicated by the 0 in the first row of the `extra_magic_morning` column). 

```{r}
df %>%
  select(date, extra_magic_morning, park, wdw_ticket_season, close, .fitted)
```
We can examine the distribution of propensity scores by exposure group. A nice way to visualize this is via "mirrored histograms". The code below creates two histograms of the propensity scores, one on the "top" for the exposed group (the dates with Extra Magic Hours in the morning) and one on the "bottom" for the unexposed group. Because we only have two variables

```{r}
ggplot() +
  geom_histogram(data = df %>% filter(extra_magic_morning == 1), 
                 aes(x = .fitted),
                 fill = "orange", 
                 bins = 25) + 
  geom_histogram(data = df %>% filter(extra_magic_morning == 0), 
                 aes(x = .fitted, 
                     y = -..count..), 
                 fill = "cornflower blue",
                 bins = 25) +
  scale_y_continuous("Count", label = abs) + 
  scale_x_continuous("Propensity Score")
```

